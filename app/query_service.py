import os
from app.embedding import embed_question
from app.pinecone_client import query_vectors
from app.utils import is_sensitive_keyword
from app.prompt_builder import chain
from dotenv import load_dotenv

load_dotenv()

SAFETY_INDEX = "adilakil-safety-minilm"
MAIN_INDEX = "adilakil-main-minilm"
SAFETY_THRESHOLD = 0.8

def get_context_with_safety_check(question):
    print(f"ğŸš€ Soru alÄ±ndÄ±: {question}")

    try:
        vec = embed_question(question)
        print(f"âœ… Embedding baÅŸarÄ±yla oluÅŸturuldu.")
    except Exception as e:
        print(f"âŒ Embedding oluÅŸturulamadÄ±: {e}")
        return {
            "safe": False,
            "message": f"Embedding hatasÄ±: {str(e)}",
            "context": None,
            "max_score": 0
        }

    try:
        safety_result = query_vectors(SAFETY_INDEX, vec, 3)
        print(f"âœ… GÃ¼venlik index sorgusu tamamlandÄ±.")
    except Exception as e:
        print(f"âŒ GÃ¼venlik index sorgusu baÅŸarÄ±sÄ±z: {e}")
        return {
            "safe": False,
            "message": f"Safety index hatasÄ±: {str(e)}",
            "context": None,
            "max_score": 0
        }

    best_match = max(safety_result.matches, key=lambda m: m.score) if safety_result.matches else None
    max_score = best_match.score if best_match else 0.0
    match_text = (best_match.metadata.get('Q') or best_match.metadata.get('question') or "").lower() if best_match else ""

    print(f"ğŸ” GÃ¼venlik kontrolÃ¼ sonucu: max_score={max_score:.2f}")

    if max_score >= SAFETY_THRESHOLD and is_sensitive_keyword(match_text):
        print(f"âš ï¸ Soru hassas iÃ§erik iÃ§eriyor. YanÄ±t verilmeyecek.")
        return {
            "safe": False,
            "message": "Bu konu hassas iÃ§erik kapsamÄ±nda olduÄŸu iÃ§in yanÄ±tlanamÄ±yor. LÃ¼tfen baÅŸka bir soru sorun.",
            "context": None,
            "max_score": max_score,
        }

    try:
        main_result = query_vectors(MAIN_INDEX, vec, 3)
        print(f"âœ… Ana index sorgusu tamamlandÄ±.")
    except Exception as e:
        print(f"âŒ Ana index sorgusu baÅŸarÄ±sÄ±z: {e}")
        return {
            "safe": False,
            "message": f"Ana index hatasÄ±: {str(e)}",
            "context": None,
            "max_score": max_score
        }

    context = "\n\n".join(
        [f"Q: {m.metadata.get('question')}\nA: {m.metadata.get('answer')}" for m in main_result.matches]
    )
    print(f"ğŸ“„ Context oluÅŸturuldu:\n{context}")

    return {
        "safe": True,
        "message": "âœ… Soru gÃ¼venli, context getirildi.",
        "context": context,
        "max_score": max_score,
    }

def get_final_answer(question):
    print(f"ğŸš€ Soru iÅŸleniyor: {question}")

    result = get_context_with_safety_check(question)
    if not result['safe']:
        print(f"âš ï¸ GÃ¼venlik nedeniyle cevap verilmiyor: {result['message']}")
        return result['message']

    context = result['context']
    print(f"ğŸ“„ Context ile LangChain zinciri Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor.")

    try:
        answer = chain.invoke({
            "context": context,
            "user_question": question
        })
        print(f"âœ… YanÄ±t alÄ±ndÄ±.")
        return answer.content
    except Exception as e:
        print(f"âŒ get_final_answer fonksiyonunda hata: {e}")
        return f"Hata oluÅŸtu: {str(e)}"
    